{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friday (prototype 2)\n",
    "A dynamic NN based assistant and framework\n",
    "\n",
    "rewritten with a Dynamic NN framework to make my life a little easier. If you would like to see a half built version in tensorflow checkout friday.ipynb\n",
    "\n",
    "NOTE: quite a bit of this notebook rips off https://github.com/ml-jku/hopfield-layers/blob/master/examples/bit_pattern/bit_pattern_demo.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This relies on the non pip package hopefield-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/ml-jku/hopfield-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general modules used e.g. for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importing Hopfield-specific modules.\n",
    "from hflayers import Hopfield\n",
    "\n",
    "# Import auxiliary modules.\n",
    "from distutils.version import LooseVersion\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Importing PyTorch specific modules.\n",
    "from torch import Tensor\n",
    "from torch.nn import Flatten, Linear, Module\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set()\n",
    "sns.set_theme(style=\"dark\") # prioritys lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Auxiliaries\n",
    "Before digging into Hopfield-based networks, a few auxiliary variables and functions need to be defined. This is nothing special with respect to Hopfield-based networks, but rather common preparation work of (almost) every machine learning setting (e.g. definition of a data loader as well as a training loop). We will see, that this comprises the most work of this whole demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [3, 3] # the input shape used in this notebook\n",
    "output_shape = [3, 3] # the output shape used in this notebook\n",
    "topic_shape = [3, 3]\n",
    "zeros = torch.zeros(input_shape)\n",
    "ones = torch.ones(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(r'cuda:0' if torch.cuda.is_available() else r'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bit_pattern_set = BitPatternSet(\n",
    "#    num_bags=2048,\n",
    "#    num_instances=16,\n",
    "#    num_signals=8,\n",
    "#    num_signals_per_bag=1,\n",
    "#    num_bits=8)\n",
    "log_dir = f'resources/'\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(network: Module,\n",
    "                optimiser: AdamW,\n",
    "                data_loader: DataLoader\n",
    "               ) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Execute one training epoch.\n",
    "    \n",
    "    :param network: network instance to train\n",
    "    :param optimiser: optimiser instance responsible for updating network parameters\n",
    "    :param data_loader: data loader instance providing training data\n",
    "    :return: tuple comprising training loss as well as accuracy\n",
    "    \"\"\"\n",
    "    network.train()\n",
    "    losses, accuracies = [], []\n",
    "    for sample_data in data_loader:\n",
    "        data, target = sample_data[r'data'], sample_data[r'target']\n",
    "        data, target = data.to(device=device), target.to(device=device)\n",
    "\n",
    "        # Process data by Hopfield-based network.\n",
    "        model_output = network.forward(input=data)\n",
    "\n",
    "        # Update network parameters.\n",
    "        optimiser.zero_grad()\n",
    "        loss = binary_cross_entropy_with_logits(input=model_output, target=target, reduction=r'mean')\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(parameters=network.parameters(), max_norm=1.0, norm_type=2)\n",
    "        optimiser.step()\n",
    "\n",
    "        # Compute performance measures of current model.\n",
    "        accuracy = (model_output.sigmoid().round() == target).to(dtype=torch.float32).mean()\n",
    "        accuracies.append(accuracy.detach().item())\n",
    "        losses.append(loss.detach().item())\n",
    "    \n",
    "    # Report progress of training procedure.\n",
    "    return (sum(losses) / len(losses), sum(accuracies) / len(accuracies))\n",
    "\n",
    "\n",
    "def eval_iter(network: Module,\n",
    "              data_loader: DataLoader\n",
    "             ) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the current model.\n",
    "    \n",
    "    :param network: network instance to evaluate\n",
    "    :param data_loader: data loader instance providing validation data\n",
    "    :return: tuple comprising validation loss as well as accuracy\n",
    "    \"\"\"\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        losses, accuracies = [], []\n",
    "        for sample_data in data_loader:\n",
    "            data, target = sample_data[r'data'], sample_data[r'target']\n",
    "            data, target = data.to(device=device), target.to(device=device)\n",
    "\n",
    "            # Process data by Hopfield-based network.\n",
    "            model_output = network.forward(input=data)\n",
    "            loss = binary_cross_entropy_with_logits(input=model_output, target=target, reduction=r'mean')\n",
    "\n",
    "            # Compute performance measures of current model.\n",
    "            accuracy = (model_output.sigmoid().round() == target).to(dtype=torch.float32).mean()\n",
    "            accuracies.append(accuracy.detach().item())\n",
    "            losses.append(loss.detach().item())\n",
    "\n",
    "        # Report progress of validation procedure.\n",
    "        return (sum(losses) / len(losses), sum(accuracies) / len(accuracies))\n",
    "\n",
    "\n",
    "def operate(network: Module,\n",
    "            optimiser: AdamW,\n",
    "            data_loader_train: DataLoader,\n",
    "            data_loader_eval: DataLoader,\n",
    "            num_epochs: int = 1\n",
    "           ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Train the specified network by gradient descent using backpropagation.\n",
    "    \n",
    "    :param network: network instance to train\n",
    "    :param optimiser: optimiser instance responsible for updating network parameters\n",
    "    :param data_loader_train: data loader instance providing training data\n",
    "    :param data_loader_eval: data loader instance providing validation data\n",
    "    :param num_epochs: amount of epochs to train\n",
    "    :return: data frame comprising training as well as evaluation performance\n",
    "    \"\"\"\n",
    "    losses, accuracies = {r'train': [], r'eval': []}, {r'train': [], r'eval': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train network.\n",
    "        performance = train_epoch(network, optimiser, data_loader_train)\n",
    "        losses[r'train'].append(performance[0])\n",
    "        accuracies[r'train'].append(performance[1])\n",
    "        \n",
    "        # Evaluate current model.\n",
    "        performance = eval_iter(network, data_loader_eval)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"---------------------------------\")\n",
    "            print(\"epoch:\", epoch, \"of\", num_epochs, \"\\naccuracy:\", performance[1], \"\\nloss:\", performance[0])\n",
    "        losses[r'eval'].append(performance[0])\n",
    "        accuracies[r'eval'].append(performance[1])\n",
    "    \n",
    "    # Report progress of training and validation procedures.\n",
    "    return pd.DataFrame(losses), pd.DataFrame(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(loss: pd.DataFrame,\n",
    "                     accuracy: pd.DataFrame,\n",
    "                     log_file: str\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Plot and save loss and accuracy.\n",
    "    \n",
    "    :param loss: loss to be plotted\n",
    "    :param accuracy: accuracy to be plotted\n",
    "    :param log_file: target file for storing the resulting plot\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "    \n",
    "    loss_plot = sns.lineplot(data=loss, ax=ax[0])\n",
    "    loss_plot.set(xlabel=r'Epoch', ylabel=r'Cross-entropy Loss')\n",
    "    \n",
    "    accuracy_plot = sns.lineplot(data=accuracy, ax=ax[1])\n",
    "    accuracy_plot.set(xlabel=r'Epoch', ylabel=r'Accuracy')\n",
    "    \n",
    "    ax[1].yaxis.set_label_position(r'right')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(log_file)\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Friday DataFrame class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_tensor(w):\n",
    "    return torch.ByteTensor(list(bytes(w, 'utf8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringdftotensor(df, labels):\n",
    "    df.at()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FridayDataset(Dataset):\n",
    "    def __init__(self, df, labels):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.topic = labels[0]\n",
    "        self.fact = labels[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        # print len(self.landmarks_frame)\n",
    "        # return len(self.landmarks_frame)\n",
    "        return len(df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = string_tensor(self.df.at[idx, self.topic])\n",
    "        target = string_tensor(self.df.at[idx, self.fact])\n",
    "        return {r'data': string_tensor(self.df.at[idx, self.topic]),  r'target': string_tensor(self.df.at[idx, self.fact])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Friday model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Friday(Module):\n",
    "    def __init__(self, input_size, num_instances):\n",
    "        super().__init__()\n",
    "        self.hopfield = Hopfield(\n",
    "            input_size=input_size,\n",
    "            hidden_size=8,\n",
    "            num_heads=8,\n",
    "            update_steps_max=3,\n",
    "            scaling=0.25)\n",
    "        self.flatten = Flatten()\n",
    "        self.output_projection = Linear(in_features=self.hopfield.output_size * num_instances, out_features=1)\n",
    "        self.flatten2 = Flatten(start_dim=0)\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.hopfield(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.output_projection(x)\n",
    "        x = self.flatten2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/beavers.csv\") #TODO add a 80/20 datset splitter \n",
    "labels = [\"animal\", \"fact\"]\n",
    "dataset = FridayDataset(df = df, labels = labels)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     beaver\n",
       "1     beaver\n",
       "2     beaver\n",
       "3     beaver\n",
       "4     beaver\n",
       "5     beaver\n",
       "6     beaver\n",
       "7     beaver\n",
       "8     beaver\n",
       "9     beaver\n",
       "10    beaver\n",
       "11    beaver\n",
       "12    beaver\n",
       "13    beaver\n",
       "14    beaver\n",
       "15    beaver\n",
       "16    beaver\n",
       "17    beaver\n",
       "18    beaver\n",
       "19    beaver\n",
       "Name: animal, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = string_tensor(df.at[1, \"animal\"])\n",
    "target = string_tensor(df.at[1, \"fact\"])\n",
    "{r'data': data, r'target': target}\n",
    "dl = len(data)\n",
    "dt = len(target)\n",
    "size = max(dl, dt)\n",
    "df[\"animal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0, 116, 101, 115, 116,   0,   0,   0,   0],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.nn.ConstantPad1d(4, 0)\n",
    "input = string_tensor(\"test\")\n",
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [4] at entry 0 and [11] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/fulton/code/ai_fun/friday2.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000023?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, n \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000023?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=72'>73</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=73'>74</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=74'>75</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=72'>73</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=73'>74</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=74'>75</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:56\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=53'>54</a>\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=54'>55</a>\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=56'>57</a>\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=57'>58</a>\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=58'>59</a>\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=59'>60</a>\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [4] at entry 0 and [11] at entry 2"
     ]
    }
   ],
   "source": [
    "for i, n in data_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Friday(input_size = 8, num_instances = len(dataset)).to(device=device)\n",
    "optimiser = AdamW(params=network.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [4] at entry 0 and [11] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/fulton/code/ai_fun/friday2.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000021?line=0'>1</a>\u001b[0m losses, accuracies \u001b[39m=\u001b[39m operate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000021?line=1'>2</a>\u001b[0m     network\u001b[39m=\u001b[39mnetwork,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000021?line=2'>3</a>\u001b[0m     optimiser\u001b[39m=\u001b[39moptimiser,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000021?line=3'>4</a>\u001b[0m     data_loader_train\u001b[39m=\u001b[39mdata_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000021?line=4'>5</a>\u001b[0m     data_loader_eval\u001b[39m=\u001b[39mdata_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000021?line=5'>6</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n",
      "\u001b[1;32m/home/fulton/code/ai_fun/friday2.ipynb Cell 9'\u001b[0m in \u001b[0;36moperate\u001b[0;34m(network, optimiser, data_loader_train, data_loader_eval, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=83'>84</a>\u001b[0m losses, accuracies \u001b[39m=\u001b[39m {\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m: [], \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m: []}, {\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m: [], \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m: []}\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=84'>85</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=85'>86</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=86'>87</a>\u001b[0m     \u001b[39m# Train network.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=87'>88</a>\u001b[0m     performance \u001b[39m=\u001b[39m train_epoch(network, optimiser, data_loader_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=88'>89</a>\u001b[0m     losses[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(performance[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=89'>90</a>\u001b[0m     accuracies[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(performance[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;32m/home/fulton/code/ai_fun/friday2.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(network, optimiser, data_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=12'>13</a>\u001b[0m network\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=13'>14</a>\u001b[0m losses, accuracies \u001b[39m=\u001b[39m [], []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample_data \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=15'>16</a>\u001b[0m     data, target \u001b[39m=\u001b[39m sample_data[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m], sample_data[\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fulton/code/ai_fun/friday2.ipynb#ch0000008?line=16'>17</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice), target\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=558'>559</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=51'>52</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=72'>73</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=73'>74</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=74'>75</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=72'>73</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=73'>74</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=74'>75</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=75'>76</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:56\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=53'>54</a>\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=54'>55</a>\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=56'>57</a>\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=57'>58</a>\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=58'>59</a>\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py?line=59'>60</a>\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [4] at entry 0 and [11] at entry 2"
     ]
    }
   ],
   "source": [
    "losses, accuracies = operate(\n",
    "    network=network,\n",
    "    optimiser=optimiser,\n",
    "    data_loader_train=data_loader,\n",
    "    data_loader_eval=data_loader,\n",
    "    num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(loss=losses, accuracy=accuracies, log_file=f'{log_dir}/hopfield_base.pdf')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
